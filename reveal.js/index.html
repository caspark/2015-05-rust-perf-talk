<!doctype html>
<html lang="en">

    <head>
        <meta charset="utf-8">

        <title>2015-05 Rust Performance Talk</title>

        <meta name="description" content="Talk on Rust performance">
        <meta name="author" content="Caspar Krieger">

        <meta name="apple-mobile-web-app-capable" content="yes" />
        <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

        <link rel="stylesheet" href="css/reveal.css">
        <link rel="stylesheet" href="css/theme/night.css" id="theme">

        <!-- Code syntax highlighting -->
        <link rel="stylesheet" href="lib/css/zenburn.css">

        <!-- Printing and PDF exports -->
        <script>
            var link = document.createElement( 'link' );
            link.rel = 'stylesheet';
            link.type = 'text/css';
            link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
            document.getElementsByTagName( 'head' )[0].appendChild( link );
        </script>

        <!--[if lt IE 9]>
        <script src="lib/js/html5shiv.js"></script>
        <![endif]-->
    </head>

    <body>

    <div class="reveal markdown">

            <!-- Any section element inside of this container is displayed as a slide -->
      <div class="slides">
        <section>
          <h2>From Java to the Metal</h2>
          <br>
          <h4>Pitting Rust against the JVM</h4>
          <br>
          <p>
            <small><a href="http://asparck.com">Caspar Krieger</a> / Java Dev @ Atlassian</small>
          </p>

          <aside class="notes">
            Talking about experiences optimizing Rust code for performance, coming from a Java/Scala background.
          </aside>
        </section>

        <section>
          <section>
            <h2>The other side of Rust</h2>

            <p>More than a better language for C/C++ devs</p>

            <aside class="notes">
              * Lot of focus on whether Rust is a suitable alternative for C/C++ devs
              * Argument about whether C++ devs will switch, etc
              * I don't really care
            </aside>
          </section>

          <section>
            <h2>Systems programming for the masses</h2>

            <p>For me, C++ is a massive footgun:</p>

            <ul>
              <li>Pointer arithmetic, use after free, etc</li>
              <li>Is X undefined behaviour?</li>
            </ul>

            <aside class="notes">
              * Write a low level language without blowing my feet off
              * Best case, I get a segfault in a particular test case
              * Worst case, I've got a mistake and I don't even realise it
              * Takes a lot of time to learn C++ properly
            </aside>
          </section>

          <section>
            <h2>Why even bother as a Java dev?</h2>

            <ul>
              <li>Infrastructure needs C-level code (e.g. Apache modules)</li>
              <li>Fast &amp; easy to distribute command line tools</li>
              <li>Game development as a hobby</li>
            </ul>

            <aside class="notes">
              * Missing piece in my toolbox
            </aside>
          </section>

          <section>
            <h2>Question</h2>
            <p>How do you get a Java dev to learn a new language like Rust?</p>

            <aside class="notes">
              - When the language is only just in Alpha state...
              - And when that language is reputed to have a steep learning curve...
              - How can I stay motivated?
            </aside>
          </section>

          <section>
            <h2>Answer</h2>
            <p>A: Do the Java-based <em>Algorithms</em> Coursera course<br>... in Rust</p>

            <aside class="notes">
              - Good because I have a piece of paper which claims that I know most of it already
              ... at least in theory
              - Do all the assignments in Rust
              - Have to rewrite a lot of provided Java code too
              - Good for adjusting known patterns to Rust
            </aside>
          </section>

          <section>
            <p>... shit, I've replaced one problem by another</p>

            <p>How do I stay motivated for the coursera course?</p>

            <aside class="notes">
              Great, gotten rid of one problem, replaced it with another
              How to stay motivated for the Coursera course?
            </aside>
          </section>

          <section>
            <h2><em>Algorithms study group</em></h2>

            <p>"For people who want to brush up on Algorithms"</p>

            <p>Most people used Java (for auto-marker), but also saw:</p>

            <ul>
              <li>Scala, Haskell</li>
              <li>Python, Perl</li>
              <li>Go, C#</li>
            </ul>

            <aside class="notes">
              - Run a study group to stay motivated
              - Java was most popular since the marker for the Course only worked for Java
              - Lots of different languages
              - What happens when people solve the same problem in different languages?
            </aside>
          </section>

          <section>
            <h2>A Competition!</h2>

            <p>Everybody wants to prove their language is the best.</p>

            <aside class="notes">
              * Got drawn into performance optimisation
              * Lots of low level details I normally never think about as a Java dev
            </aside>
          </section>
        </section>

        <section>
          <h2>let's optimize some real Rust</h2>

          <aside class="notes">
            * Touch on some tools for optimising Rust code
            * (probably familiar to C/C++ people)
            * Also shows off some real Rust code
            * Helpful for beginners
          </aside>
        </section>

        <section>
          <h2>but first, a big disclaimer</h2>

          <h3>My Rust experience level:</h3>

          <ul>
            <li>4 months, ~4k lines of Rust</li>
            <li>Code not reviewed</li>
            <li>I (try to) write Rust like it's Scala</li>
            <li>Negligible C/C++ experience</li>
          </ul>

          <p>If Huon hadn't bribed with me a t-shirt, I'd be in the audience.</p>

          <aside class="notes">
            * Many small projects is great, especially when the language is changing every week
            * Get to apply new learnings to new code regularly
            * I'm not an expert. At best, I'm approaching competence!
            * My code probably isn't idiomatic
            * I trust Huon will shout at me if I get major things wrong
          </aside>
        </section>

        <section>
          <section>
            <h2>Our problem: <a href="http://coursera.cs.princeton.edu/algs4/assignments/seamCarving.html">seam carving</a></h2>

            <ul>
              <li>A clever way to resize images</li>
              <li>Remove the least interesting vertical slices of the image</li>
            </ul>
            <br>
            <img src="./img/HJoceanSmall.png">
            <img src="./img/HJoceanSmallShrunk.png">

            <aside class="notes">
              * 150 pixel slices removed
              * Water between surfers has been removed
              * Water on right has been removed
              * Some slices of land on the left have been removed
            </aside>
          </section>

          <section>
            <h2>First calculate pixel energies</h2>

            <p>Energy is how interesting the pixel is.</p>
            <img src="./img/HJoceanSmallEnergy-autolevelled.png">
            <p><strong>Why?</strong> Want to avoid removing interesting pixels.</p>

            <aside class="notes">
              * Algorithm operates in 2 stages
              * First stage is finding the energy of each pixel
              * This sample picture is photoshopped to make the energy more obvious
              * Energy of a given pixel is calculated by the difference in colour of surrounding pixels
              * Won't show calculation or code to save time.
            </aside>
          </section>

          <section>
            <h2>Now find min-energy seam</h2>

            <p>From each pixel, either go down + left, down, or down + right, depending on which pixel has the least energy.</p>

            <img src="./img/HJoceanSmallVerticalSeam-autolevelled.png">

            <p>Then remove this seam (and rinse and repeat).</p>

            <aside class="notes">
              * Stage 2 is to use the calculated energy to find the path of minimum energy.
              * Because we're trying to find a line of pixels, the search from each pixel only has 3 options.
              * Again, image is photoshopped.
            </aside>
          </section>

          <section>
            <h2>Calculating min-energy seam</h2>

            <p>For each pixel, see if using this pixel to get to<br>
              each next pixel option results in a better seam</p>

            <pre><code data-trim>
// rust-like pseudocode
for pixel in all_pixels {
    //   p     &lt;- p is `pixel`
    // 1 2 3   &lt;- `pixel_option` is one of the three pixels below `pixel`
    for pixel_option in find_pixel_options(pixel) {
        if is_best_path_to_pixel_option(pixel, pixel_option) {
            record_best_path_to_pixel_option(pixel, pixel_option);
        }
    }
}
            </code></pre>
            <p>(If `pixel` is on edge of image, there are only 2 `pixel_option`s)</p>
            <aside class="notes">
              - This is checking whether the pixel can provide a better path to to_pixel than is already recorded.
            </aside>
          </section>

          <section>
            <h2>Same again, but now in Rust</h2>
            <pre><code data-trim>
pub fn find_seam(&amp;mut self, width: usize, height: usize) -> Vec&lt;usize&gt; {
    for pixel in 0..(num_pixels - width) {
        let next_pixel_options = if pixel % width == 0 { // first column
            vec![pixel + width, pixel + width + 1]
        } else if (pixel + 1) % width == 0 { // last column
            vec![pixel + width - 1, pixel + width]
        } else {
            vec![pixel + width - 1, pixel + width, pixel + width + 1]
        };

        for pixel_option in next_pixel_options {
            if self.dist_to[pixel_option] &gt;
                        self.dist_to[pixel] + self.energy[pixel_option] {
                self.dist_to[pixel_option] =
                        self.dist_to[pixel] + self.energy[pixel_option];
                self.prev_vertex[pixel_option] = pixel;
            }
        }
    }
    // [finally loop through self.prev_vertex to find the best path]
}
            </code></pre>

            <aside class="notes">
              - Use modulus to figure out whether we're on the edge to do special case handling
              - Store the reachable pixel options in a vec, and then loop through them to see if the current pixel provides a better path to them
              - self.dist_to records the cost of the best path to a given pixel
              - self.prev_vertex records the previous vertex
              - Then remove that slice found.
            </aside>
          </section>
        </section>

        <section>
          <h2>How does that perform?</h2>
          <div class="fragment">
            <ul>
                <li>~1600ms to remove 300 pixels from a 507 x 285 image</li>
                <li>Worse than Java :(</li>
                <li>Let's profile it to see how make it faster!</li>
            </ul>
          </div>

          <aside class="notes">
            * So that's reasonable code - how does it do?
            * JVM has had years of tuning so that's not surprising
          </aside>
        </section>

        <section>
          <h2>Readable profiling results</h2>
          <ul>
            <li>debug builds (<code>cargo build</code>) are not optimised</li>
            <li>release builds (<code>cargo build --release</code>) have no debug info</li>
            <li>solution: add debug info to release builds</li>
          </ul>
          <pre><code data-trim>
# in Cargo.toml
[profile.release]
debug = true
          </code></pre>
          <aside class="notes">
            - I think including debug info could affect profiling, but that's a risk I have to take
          </aside>
        </section>

        <section>
          <section>
            <h2><a href="http://valgrind.org/">Valgrind</a>, or rather, <a href="http://valgrind.org/docs/manual/cl-manual.html">Callgrind</a></h2>

            <pre><code data-trim>
$ valgrind --tool=callgrind --callgrind-out-file=callgrind.out \
    ./target/release/2-seam-carving test-input.png -W 100
$ callgrind_annotate callgrind.out
            </code></pre>

            <p><code>callgrind_annotate</code> gives you a list of functions<br>(sorted by executed instruction count)</p>

            <br>

            <ul>
              <li>Pro tip #1: avoid profiling cargo! Run binary directly.</li>
              <li>Pro tip #2: use smaller inputs - callgrind is slow.</li>
            </ul>

            <aside class="notes">

              * Callgrind is a tool shipped with valgrind which records calls made to functions
              * callgrind_annotate can show source too but is otherwise minimal, so use another tool for looking at results
            </aside>
          </section>

          <section>
            <h2><a href="http://kcachegrind.sourceforge.net/html/Home.html">kcachegrind</a></h2>

            <ul>
              <li>callgrind is based on another valgrind tool, <a href="http://valgrind.org/docs/manual/cg-manual.html">cachegrind</a></li>
              <li>kcachegrind handles output files from both</li>
              <li>much nicer output than callgrind_annotate</li>
              <li>also handles recursive code properly</li>
            </ul>

            <p>Tip: go to Settings &gt; Configure Kcachegrind &gt; Annotations,<br>then add Rust source code dir.</p>

            <aside class="notes">
              * if you don't add Rust source code then inline code won't have available source
              * Rust compiler (or llvm) inlines a lot of stuff, so that's pretty annoying
            </aside>
          </section>

          <section>
            <img class="stretch" src="./img/kcachegrind.png">

            <aside class="notes">
              screenshot of kcachegrind on callgrind output of our program
            </aside>
          </section>

          <section>
            <img class="stretch" src="./img/kcachegrind-allocations.png">

            <aside class="notes">

              - zoom in showing that je_mallocx and je_sdsallocx are making things slow
              - where are we allocating memory?
            </aside>
          </section>

          <section>
            <h2>Cause of memory allocations</h2>
            <pre><code data-trim>
pub fn find_seam(&amp;mut self, width: usize, height: usize) -> Vec&lt;usize&gt; {
    for pixel in 0..(num_pixels - width) {
        let next_pixel_options = if pixel % width == 0 {
            vec![pixel + width, pixel + width + 1] // ALLOCATION
        } else if (pixel + 1) % width == 0 {
            vec![pixel + width - 1, pixel + width] // ALLOCATION
        } else {
            vec![pixel + width - 1, pixel + width, pixel + width + 1] // ALLOCATION
        };

        for pixel_option in next_pixel_options {
            if self.dist_to[pixel_option] &gt;
                        self.dist_to[pixel] + self.energy[pixel_option] {
                self.dist_to[pixel_option] =
                        self.dist_to[pixel] + self.energy[pixel_option];
                self.prev_vertex[pixel_option] = pixel;
            }
        }
    }
    // [finally loop through self.prev_vertex to find the best path]
}
            </code></pre>

            <aside class="notes">
              - marked lines are creating Vecs, which store their contents on the heap (because it's a growable data type)
              - how can we fix this?
            </aside>
          </section>

          <section>
            <h2>Avoiding heap allocations</h2>
            <pre class="stretch"><code data-trim>
pub fn find_seam(&amp;mut self, width: usize, height: usize) -> Vec&lt;usize&gt; {
    for pixel in 0..(num_pixels - width) {
        let tmp_len_2;
        let tmp_len_3;
        let next_pixel_options: &amp;[usize] = if pixel % width == 0 { // first column
            tmp_len_2 = [pixel + width, pixel + width + 1];
            &amp;tmp_len_2
        } else if (pixel + 1) % width == 0 { // last column
            tmp_len_2 = [pixel + width - 1, pixel + width];
            &amp;tmp_len_2
        } else {
            tmp_len_3 = [pixel + width - 1, pixel + width, pixel + width + 1];
            &amp;tmp_len_3
        };

        // (no changes below this point)
        for pixel_option in next_pixel_options {
            if self.dist_to[pixel_option] &gt;
                        self.dist_to[pixel] + self.energy[pixel_option] {
                self.dist_to[pixel_option] =
                        self.dist_to[pixel] + self.energy[pixel_option];
                self.prev_vertex[pixel_option] = pixel;
            }
        }
    }
    // [finally loop through self.prev_vertex to find the best path]
}
            </code></pre>

            <aside class="notes">
              - 1600 ms -> 1150 ms (30% faster)
              - Allocate 2 fixed-size arrays on the stack
              - Return a reference to them
              - Rust is clever enough to avoid complaining about un-initialised variables
              - Rest of the code doesn't need to change
            </aside>
          </section>

          <section>
            <h2>or use a closure</h2>
            <pre class="stretch"><code data-trim>
pub fn find_seam(&amp;mut self, width: usize, height: usize) -> Vec&lt;usize&gt; {
        let mut relax_edge = |from_pixel: usize, to_pixel: usize| {
            if self.dist_to[to_pixel] > self.dist_to[from_pixel] + self.energy[to_pixel] {
                self.dist_to[to_pixel] = self.dist_to[from_pixel] + self.energy[to_pixel];
                self.prev_vertex[to_pixel] = from_pixel;
            }
        };

        // each pixel in the image has an edge to the pixel below and the pixel to the left and right of that
        for pixel in 0..(num_pixels - width) {
            if pixel % width == 0 { // first column
                relax_edge(pixel, pixel + width);
                relax_edge(pixel, pixel + width + 1);
            } else if (pixel + 1) % width == 0 { // last column
                relax_edge(pixel, pixel + width - 1);
                relax_edge(pixel, pixel + width);
            } else {
                relax_edge(pixel, pixel + width - 1);
                relax_edge(pixel, pixel + width);
                relax_edge(pixel, pixel + width + 1);
            }
        }
    }
    // [finally loop through self.prev_vertex to find the best path]
}
            </code></pre>

            <aside class="notes">
              - Or we can do the same thing using a closure
              - Approx same speed as using stack allocated array
              - Suspect Rust inlines the closure
              - A method in this case would work too, but it's slower unless hinted with #[inline(always)]
            </aside>
          </section>
        </section>

        <section>
          <h2>Now what?</h2>

          <p>kcachegrind says the slowest line of code now is:</p>
          <pre><code data-trim>
            if self.dist_to[to_pixel] > self.dist_to[from_pixel] + self.energy[to_pixel] {
          </code></pre>
          <p>but I don't see an easy way to speed that up.</p>
        </section>

        <section>
          <section>
            <h2>Using Linux's <a href="https://perf.wiki.kernel.org/index.php/Main_Page">perf</a> instead</h2>
            <pre><code data-trim>
$ perf record ./target/release/2-seam-carving test-input.png -W 300
$ perf report
            </code></pre>

            <ul>
              <li>Bonus: <code>perf</code> is faster so remove a full 300 pixels</li>
            </ul>

            <aside class="notes">
              * Don't know much about perf - Huon showed me this trick so direct all your questions to him
            </aside>
          </section>

          <section>
            <img class="stretch" src="img/perf-report-of-modulus.png">

            <aside class="notes">
              * I'm mostly a stranger to disassembly
              * Thankfully perf report highlights the slow bits in red
              * Based on the source there, the modulus is the slowest bit
              * Can we avoid the modulus? Yep.
              * actually when I rewrote this code first time, I just cached the first modulus and used it for the second check
              * but let's skip straight to the better code
            </aside>
          </section>

          <section>
            <h2>Joys of nested loops</h2>

            <pre><code data-trim>
 for y in 0..(height - 1) {
     let height_offset = y * width;

     relax_edge(height_offset, height_offset + width);
     relax_edge(height_offset, height_offset + width + 1);

     for x in 1..(width - 1) {
         let pixel = height_offset + x;
         relax_edge(pixel, pixel + width - 1);
         relax_edge(pixel, pixel + width);
         relax_edge(pixel, pixel + width + 1);
     }

     let last_col_pixel = height_offset + width - 1;
     relax_edge(last_col_pixel, last_col_pixel + width - 1);
     relax_edge(last_col_pixel, last_col_pixel + width);
 }
            </code></pre>

            <aside class="notes">
              - we've added an inner loop
              - and unrolled some of the inner loop so we have no ifs there either
              - we can use a similar trick for energy calculation
              - 1.2 seconds to 0.5 seconds - 60% faster!
            </aside>
          </section>
        </section>

        <section>
          <h2>Ideas for more speed?</h2>

          <ul>
            <li>Indexing is still slow - cache & use windows when iterating?</li>
            <li>Copy paste closure and manually cache data from earlier checks</li>
            <li>Cheat by using parallelism ;-)</li>
          </ul>

          <aside class="notes">
            * Not including algorithm tricks, which I haven't explored here.
            ** Obvious one is no need to relax edge between a side pixel and the one below it
            ** Also don't need to recalculate all the energy from scratch
            * Just for fun, what if we didn't need to do bounds checks when indexing?
          </aside>
        </section>

        <section>
          <h2>unsafe { #yolo }</h2>
          <pre><code data-trim>
unsafe {
    let mut relax_edge = |from_pixel: usize, to_pixel: usize| {
        if *self.dist_to.get_unchecked(to_pixel) >
                *self.dist_to.get_unchecked(from_pixel) +
                *self.energy.get_unchecked(to_pixel) {
            *self.dist_to.get_unchecked_mut(to_pixel) =
                *self.dist_to.get_unchecked(from_pixel) +
                *self.energy.get_unchecked(to_pixel);
            *self.prev_vertex.get_unchecked_mut(to_pixel) = from_pixel;
        }
    };
}
          </code></pre>

          <p>Unsafety everywhere takes us from 450 ms to 300 ms</p>
          <p>Useful: quantifies cost of bounds checking</p>

          <aside class="notes">
            * A sample of using unsafe techniques to avoid bounds checks
            * Important note: 150ms speedup isn't just from this snippet (e.g. also from energy calculation)
            * Even with this unsafety, the client code is still safe, which is nice.
            * Even if we don't keep this, then it's useful as a lower bound for our optimisation efforts: we know bounds checking isn't taking more than 150ms.
          </aside>
        </section>

        <section>
          <h2>Recap of gains</h2>

          <pre>
    Basic version                                     1.65 s ||||||||||||||||
    Avoid per pixel heap allocations                  1.25 s ||||||||||||
    Use closure rather than stack allocated array     1.22 s ||||||||||||
    Cache modulo when finding edges of image           .90 s |||||||||
    Use nested loops to avoid using modulus            .44 s ||||
    Bypass bounds checking by using unsafe indexing    .31 s |||
          </pre>

          <p>~4x better performance!</p>
          <p>(or ~5x better if using unsafe)</p>
        </section>

        <section>
          <h2>Thanks!</h2>
          <br>
          <p>
            Seam carving code for each step of gains at<br>
            <a href="https://github.com/caspark/2015-05-rust-perf-talk-code">github.com/caspark/2015-05-rust-perf-talk-code</a>
          </p>
          <br>
          <p>
            Slides + scripts to benchmark &amp; profile each step at
            <a href="https://github.com/caspark/2015-05-rust-perf-talk">github.com/caspark/2015-05-rust-perf-talk</a>
          </p>

          <aside class="notes">
            * Questions?
          </aside>
        </section>

            </div>
        </div>

        <script src="lib/js/head.min.js"></script>
        <script src="js/reveal.js"></script>

        <script>

            // Full list of configuration options available at:
            // https://github.com/hakimel/reveal.js#configuration
            Reveal.initialize({
                controls: true,
                progress: true,
                history: true,
                center: true,
        width: "960",
        height: "700",
        maxScale: 2.0,
        margin: 0.0,

                transition: 'slide', // none/fade/slide/convex/concave/zoom

                // Optional reveal.js plugins
                dependencies: [
                    { src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
                    { src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
                    { src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
                    { src: 'plugin/highlight/highlight.js', async: true, condition: function() { return !!document.querySelector( 'pre code' ); }, callback: function() { hljs.initHighlightingOnLoad(); } },
                    { src: 'plugin/zoom-js/zoom.js', async: true },
                    { src: 'plugin/notes/notes.js', async: true }
                ]
            });

        </script>

    </body>
</html>
